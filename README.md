# 2D to 3D Medical Image Colorization

A deep learning project for converting grayscale 2D medical images into colorized 3D representations using U-Net and 3D CNN architecture.

## ğŸ¯ Project Overview

This project implements a hybrid deep learning approach to:
- Colorize grayscale medical images (X-rays, CT scans, MRI)
- Generate 3D volumetric representations from 2D slices
- Provide accurate medical image visualization

## ğŸ—ï¸ Architecture

- **Stage 1**: U-Net for 2D colorization (LAB color space)
- **Stage 2**: 3D CNN for depth estimation and volumetric reconstruction
- **Loss Functions**: Perceptual loss, L1 reconstruction, SSIM

## ğŸ“ Project Structure

```
medical-image-colorization-3d/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Original DICOM/images
â”‚   â”œâ”€â”€ processed/        # Preprocessed data
â”‚   â””â”€â”€ augmented/        # Augmented dataset
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ unet.py          # U-Net architecture
â”‚   â”œâ”€â”€ reconstruction_3d.py  # 3D reconstruction network
â”‚   â””â”€â”€ colorization_model.py # Complete model
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ preprocessing.py  # Data preprocessing
â”‚   â”œâ”€â”€ visualization.py  # Visualization tools
â”‚   â”œâ”€â”€ metrics.py       # Evaluation metrics
â”‚   â””â”€â”€ data_loader.py   # Dataset loaders
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train.py         # Training script
â”‚   â”œâ”€â”€ validate.py      # Validation script
â”‚   â””â”€â”€ config.py        # Configuration
â”œâ”€â”€ inference/
â”‚   â””â”€â”€ predict.py       # Inference script
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ experiments.ipynb # Jupyter experiments
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/Akshatha258/medical-image-colorization-3d.git
cd medical-image-colorization-3d

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Data Preparation

```bash
# Place your medical images in data/raw/
python utils/preprocessing.py --input data/raw --output data/processed
```

### Training

```bash
# Train the model
python training/train.py --config training/config.py --epochs 100
```

### Inference

```bash
# Generate colorized 3D images
python inference/predict.py --input path/to/image.dcm --output results/
```

## ğŸ“Š Datasets

Recommended datasets:
- NIH Chest X-ray Dataset
- LIDC-IDRI (Lung CT)
- BraTS (Brain MRI)
- Medical Segmentation Decathlon

## ğŸ› ï¸ Technical Stack

- **Framework**: PyTorch
- **Medical Imaging**: PyDICOM, SimpleITK, NiBabel
- **Visualization**: Matplotlib, VTK, Plotly
- **Training**: PyTorch Lightning, Weights & Biases

## ğŸ“ˆ Evaluation Metrics

- PSNR (Peak Signal-to-Noise Ratio)
- SSIM (Structural Similarity Index)
- LPIPS (Learned Perceptual Image Patch Similarity)
- 3D IoU (Intersection over Union)

## ğŸ”¬ Model Details

### U-Net Colorization Network
- Encoder: 5 downsampling blocks
- Decoder: 5 upsampling blocks with skip connections
- Output: LAB color space (L channel from input, predict AB)

### 3D Reconstruction Network
- Input: Colorized 2D slices
- 3D Convolutions with residual connections
- Output: Volumetric 3D representation

## ğŸ“ License

MIT License

## ğŸ‘¥ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Contact

For questions or collaboration, please open an issue.

## ğŸ™ Acknowledgments

- U-Net architecture based on Ronneberger et al.
- Medical imaging preprocessing inspired by MONAI framework
